{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p><center style=\"font-family:newtimeroman;font-size:180%;\"> Rice Variety Classification and Quality Evaluation Using Image Analysis </center></p>\n### Table of contents:\n\n* [Introduction](#1)\n* [Import Libraries](#2)\n* [Create a Data Frame with the Image and Label](#3)\n* [Visualization Of Dataset](#4)\n* [Split Data into Train and Test](#5)\n* [Data Augmentation](#6)\n* [Train CNN Model](#7)\n* [Evaluate The Model](#8)\n* [Save Model](#9)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"**<a id=\"1\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Introduction </p>","metadata":{"execution":{"iopub.status.busy":"2023-08-14T19:17:39.966306Z","iopub.execute_input":"2023-08-14T19:17:39.967019Z"}}},{"cell_type":"markdown","source":"<html>\n<body>\n  <h1>Rice Variety Classification and Quality Evaluation Using Image Analysis</h1>\n  <p>Rice, as one of the most prevalent grain crops globally, exhibits significant genetic diversity, resulting in various rice varieties. These varieties exhibit variations in essential characteristics such as texture, shape, and color. By harnessing these differentiating features, it becomes possible to accurately classify and assess the quality of rice seeds.\n\nThis research initiative aims to develop a robust image analysis system capable of automatically identifying and categorizing different rice varieties based on their visual attributes. By employing advanced machine learning techniques and deep neural networks, the project endeavors to create a model that can accurately classify rice samples into the five target varieties.\n\nAdditionally, the developed image analysis model can contribute to the broader field of computer vision and pattern recognition. The insights gained from this research can be applied to other grain crops and agricultural products, leading to advancements in automated classification and quality evaluation across various agricultural domains.\n\nIn summary, the Rice Variety Classification and Quality Evaluation project utilizes a comprehensive dataset of 75,000 rice images to develop a state-of-the-art image analysis system. By accurately classifying and evaluating the quality attributes of five distinct rice varieties, this research aims to enhance rice production processes, support seed selection, and drive advancements in computer vision for agricultural applications.\nFor more information about the dataset use the following Kaggle link:<br>\nhttps://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset</p>\n</body>\n</html>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\">Import Libraries </p>","metadata":{}},{"cell_type":"code","source":"# import requirement libraries and tools\nimport os\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style= \"darkgrid\", color_codes = True)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:03.790757Z","iopub.execute_input":"2023-08-15T09:07:03.791404Z","iopub.status.idle":"2023-08-15T09:07:13.853076Z","shell.execute_reply.started":"2023-08-15T09:07:03.791326Z","shell.execute_reply":"2023-08-15T09:07:13.852150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\">Create a dataframe with the Images and Label </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Set the path to the dataset\ndataset_path = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset'\n\n# Initialize empty lists for storing the images and labels\nimages = []\nlabels = []\n\n# Loop over the subfolders in the dataset\nfor subfolder in os.listdir(dataset_path):\n    \n    subfolder_path = os.path.join(dataset_path, subfolder)\n    if not os.path.isdir(subfolder_path):\n        continue\n  \n  # Loop over the images in the subfolder\n    for image_filename in os.listdir(subfolder_path):\n       # Load the image and store it in the images list\n        image_path = os.path.join(subfolder_path, image_filename)\n        images.append(image_path)\n    \n        # Store the label for the image in the labels list\n        labels.append(subfolder)\n \n # Create a pandas DataFrame from the images and labels\ndf = pd.DataFrame({'image': images, 'label': labels})","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:13.854871Z","iopub.execute_input":"2023-08-15T09:07:13.855409Z","iopub.status.idle":"2023-08-15T09:07:16.524198Z","shell.execute_reply.started":"2023-08-15T09:07:13.855378Z","shell.execute_reply":"2023-08-15T09:07:16.522922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<a id=\"4\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\">Visualization of Dataset </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:16.525574Z","iopub.execute_input":"2023-08-15T09:07:16.525993Z","iopub.status.idle":"2023-08-15T09:07:16.550388Z","shell.execute_reply.started":"2023-08-15T09:07:16.525956Z","shell.execute_reply":"2023-08-15T09:07:16.549341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the classes\nax = sns.countplot(x=df.label)\n\n# Set labels and titles\nax.set_xlabel(\"Name of Class\")\nax.set_ylabel(\"The Number Of Samples for each class\")\n\n# Rotate x-axis labels if needed\nplt.xticks(rotation=45)\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T10:41:59.915459Z","iopub.execute_input":"2023-08-15T10:41:59.916088Z","iopub.status.idle":"2023-08-15T10:42:00.228627Z","shell.execute_reply.started":"2023-08-15T10:41:59.916053Z","shell.execute_reply":"2023-08-15T10:42:00.227425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.gridspec import GridSpec\n# Create figure and grid of subplots\nfig = plt.figure(figsize=(15, 15))\ngs = GridSpec(5, 4, figure=fig)\n\n# Loop through each unique category in the DataFrame\nfor i, category in enumerate(df['label'].unique()):\n    # Get the filepaths for the first four images in the category\n    filepaths = df[df['label'] == category]['image'].values[:4]\n    \n    # Loop through the filepaths and add an image to each subplot\n    for j, filepath in enumerate(filepaths):\n        ax = fig.add_subplot(gs[i, j])\n        ax.imshow(plt.imread(filepath))\n        ax.axis('off')\n    \n    # Add a label to the bottom of the subplot grid\n    ax.text(300, 100, category, fontsize=25, color='darkblue')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:16.934952Z","iopub.execute_input":"2023-08-15T09:07:16.935630Z","iopub.status.idle":"2023-08-15T09:07:19.278445Z","shell.execute_reply.started":"2023-08-15T09:07:16.935598Z","shell.execute_reply":"2023-08-15T09:07:19.277219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\">Split Data into Train and Test </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"I divided our data into two separate datasets: the training dataset and the testing dataset. The training dataset consists of 80% of the data, while the testing dataset contains the remaining 20%.\n\nTo facilitate the training process, I applied the LabelEncoder to labels. This process allowed us to convert the rice types' labels, namely 'Arborio', 'Basmati', 'Ipsala', 'Jasmine', and 'Karacadag', into numerical values. By assigning integer values to the labels, we enabled the utilization of these labels as target variables during the training of our machine learning model.","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df['image'], df['label'], test_size=0.2, random_state=42)\n\n# Create a dataframe for the training data\ndf_train = pd.DataFrame({'image': X_train, 'label': y_train})\n\n# Create a dataframe for the test data\ndf_test = pd.DataFrame({'image': X_test, 'label': y_test})\n\n# Encode the labels\nencoder = LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:19.279665Z","iopub.execute_input":"2023-08-15T09:07:19.279982Z","iopub.status.idle":"2023-08-15T09:07:19.337053Z","shell.execute_reply.started":"2023-08-15T09:07:19.279954Z","shell.execute_reply":"2023-08-15T09:07:19.336054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Data Augmentation </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"To streamline the preprocessing of our images, we took the following steps. First, we created generators for both the training and testing datasets. These generators allow us to efficiently handle and manipulate the data during the training and testing phases.\n\nMoreover, to enhance the diversity and robustness of our training data, we applied data augmentation techniques specifically to the training dataset. This augmentation process introduces variations in the images by applying transformations such as rotation, scaling, and flipping. By doing so, we expand the dataset and enable our model to learn from a wider range of image variations.\n\nAdditionally, we standardized the image dimensions by reshaping them to a uniform size of 50x50 pixels. This resizing ensures that all images in the dataset have consistent dimensions, facilitating the subsequent processing and analysis stages.","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n# Set the image size and batch size\nimage_size = (50, 50)\nbatch_size = 32\n\n# Create an ImageDataGenerator object with data augmentation options for image preprocessing\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=45,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n\n# Create a generator for the training data\ntrain_generator = datagen.flow_from_dataframe(\n    df_train,\n    x_col='image',\n    y_col='label',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\n\n# Create a generator for the test data\ntest_generator = datagen.flow_from_dataframe(\n    df_test,\n    x_col='image',\n    y_col='label',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:07:19.338516Z","iopub.execute_input":"2023-08-15T09:07:19.339088Z","iopub.status.idle":"2023-08-15T09:10:16.264476Z","shell.execute_reply.started":"2023-08-15T09:07:19.339058Z","shell.execute_reply":"2023-08-15T09:10:16.263456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Modeling </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n# Set the input shape for the model\ninput_shape = (50, 50, 3)\n\n# Create a Sequential model\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:10:16.265719Z","iopub.execute_input":"2023-08-15T09:10:16.266022Z","iopub.status.idle":"2023-08-15T09:10:16.513857Z","shell.execute_reply.started":"2023-08-15T09:10:16.265995Z","shell.execute_reply":"2023-08-15T09:10:16.512702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:10:16.515250Z","iopub.execute_input":"2023-08-15T09:10:16.515588Z","iopub.status.idle":"2023-08-15T09:10:16.533482Z","shell.execute_reply.started":"2023-08-15T09:10:16.515559Z","shell.execute_reply":"2023-08-15T09:10:16.532504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model on the training data\nhistory = model.fit_generator(train_generator,epochs=10,validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:10:16.534582Z","iopub.execute_input":"2023-08-15T09:10:16.534885Z","iopub.status.idle":"2023-08-15T09:59:56.960290Z","shell.execute_reply.started":"2023-08-15T09:10:16.534860Z","shell.execute_reply":"2023-08-15T09:59:56.958916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Evaluate The Model  </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"code","source":"#Accuracy comparison between Validation and Train Data set\nplt.figure(figsize=(10,6))\nplt.plot(history['accuracy'],color=\"#E74C3C\",marker='o')\nplt.plot(history['val_accuracy'],color='#641E16',marker='h')\nplt.title('Accuracy comparison between Validation and Train Data set',fontsize=15)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T10:11:59.793803Z","iopub.execute_input":"2023-08-15T10:11:59.794299Z","iopub.status.idle":"2023-08-15T10:12:00.176021Z","shell.execute_reply.started":"2023-08-15T10:11:59.794263Z","shell.execute_reply":"2023-08-15T10:12:00.174758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loss comparison between Validation and Train Data set\nplt.figure(figsize=(10,6))\nplt.plot(history['loss'],color=\"#E74C3C\",marker='o')\nplt.plot(history['val_loss'],color='#641E16',marker='h')\nplt.title('Loss comparison between Validation and Train Data set',fontsize=15)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='best')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-15T10:12:13.892292Z","iopub.execute_input":"2023-08-15T10:12:13.893750Z","iopub.status.idle":"2023-08-15T10:12:14.267178Z","shell.execute_reply.started":"2023-08-15T10:12:13.893712Z","shell.execute_reply":"2023-08-15T10:12:14.266131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test data\nmetrics = model.evaluate(test_generator)\n# Print the accuracy of the model\nprint('Accuracy:', metrics[1])","metadata":{"execution":{"iopub.status.busy":"2023-08-15T10:12:20.304320Z","iopub.execute_input":"2023-08-15T10:12:20.304769Z","iopub.status.idle":"2023-08-15T10:12:56.428224Z","shell.execute_reply.started":"2023-08-15T10:12:20.304737Z","shell.execute_reply":"2023-08-15T10:12:56.427216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Save Model  </p>\n<a class=\"btn\" href=\"#home\">Tabel of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodel.save('CNN_model.h5')\nprint (\"Model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T10:24:34.318967Z","iopub.execute_input":"2023-08-15T10:24:34.319383Z","iopub.status.idle":"2023-08-15T10:24:34.367892Z","shell.execute_reply.started":"2023-08-15T10:24:34.319335Z","shell.execute_reply":"2023-08-15T10:24:34.367111Z"},"trusted":true},"execution_count":null,"outputs":[]}]}